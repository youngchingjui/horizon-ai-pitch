# Workplan & Timeline (12 weeks)

## Cadence

• Weekly: Mon planning (30m), Tue/Thu build, Fri demo (30–45m).
• Biweekly: Champion Clinic (90m), adoption/metrics review (30m).
• Monthly: Exec Readout (30m) led by Amanda.

## Phase 1 – Discover & Baseline (Weeks 1–2)

- Intake workshops per function (60–90m each) to map top workflows and pain points.
- Instrument baselines: pull existing system metrics (funnel/CS/ops), capture current macros/templates, and define lightweight telemetry; optional pulse survey for perceived time saved. No stopwatch time studies (to reduce burden/cost).
- Select 10 pilot candidates using an Impact × Feasibility scorecard.
- **Deliverable**: Pilot Backlog v1, Measurement Plan, AI Policy & Guardrails (2‑page).

---

# Workplan & Timeline (12 weeks)

## Phase 2 – Train & Prototype (Weeks 3–6)

- AI Core (2 x 90m) for all participants: prompt patterns, critique loops, verification, retrieval, and safe data use.
- Function Labs (2 x 60m) per team with hands‑on assets (templates, checklists).
- Build 10 pilots in 1‑week sprints (2 per function), with shadow runs in Weeks 4–5 and 3–5 going live by Week 6.
- **Deliverable**: Friday Demos (recorded), Template Library v1, Pilot scorecards.

---

# Workplan & Timeline (12 weeks)

## Phase 3 – Deploy, Scale, Handoff (Weeks 7–12)

- Productionize best pilots (target 5–7), add monitoring and fallback SOPs.
- Expand to adjacent workflows; create Run Books and Champion Playbooks.
- Build Adoption Dashboard (usage, quality scores, funnel/support KPIs).
- **Deliverable**: AI Wins Digest (Weeks 8 & 12), Final Report, Roadmap for global rollout.

---

# Workplan & Timeline (12 weeks)

## Optional – Long‑term usage validation (+1w, +1m, +1q)

- Quick check‑ins after the 12‑week program: review usage dashboards and run a 2‑minute pulse survey.
- Run a "can we remove this tool?" litmus test with Champions; track objections as a success signal.
- Share a brief retention report and recommendations; trigger outcome‑tied bonus if sustained usage is confirmed.

