1. Executive Summary — “AI‑First China Lighthouse”

We’ll run a 12‑week change‑management program across Sales, Marketing, CSM, Operations, and Support in China. The program combines short, high‑leverage training with tightly scoped pilots, measured against clear baseline metrics. Every Friday we demo what shipped. By Week 6 we will have at least 5 productionized wins and a public “AI Wins” digest Amanda can share with the global leadership team. By Week 12 we hand over playbooks, dashboards, and an internal “AI Champion” network so China can scale independently and Amanda can sponsor the global rollout.

⸻

1. Objectives & Success Criteria

Business objectives
• 20–30% time saved on 3+ high‑volume workflows per function (measured by time studies).
• Faster revenue motions: +15% more qualified meetings/week per AE (Sales), +10% reply rate uplift on personalized outbound (Marketing/Sales).
• Customer outcomes: −20% median first response time (Support), +10% increase in proactive health check touchpoints (CSM).
• Ops throughput: automate 3 repetitive workflows (e.g., document prep, reconciliations) with ≥95% accuracy in shadow runs.

Adoption objectives
• 80% of target users complete “AI Core” training and pass a short skills check.
• 5 cross‑function AI Champions established in China with weekly office hours.
• Central library of 30+ vetted prompts/templates + 10 SOPs integrated into existing tools.

Executive‑level win
• Monthly “AI Wins” digest and a 30‑minute show‑and‑tell for the global LT by Week 6 highlighting China’s results (Amanda as sponsor/MC).

⸻

2. Scope, Assumptions, Guardrails

In scope: process redesign + AI enablement for Sales, Marketing, CSM, Ops, Support in China
Assumptions: access to CRM (HubSpot/Salesforce), ticketing (e.g., Zendesk/Freshdesk), BI (Power BI), knowledge base (Notion/Confluence/SharePoint); LLM access in China (e.g., DeepSeek/Kimi/ERNIE) and/or a VPN‑approved enterprise LLM.
Guardrails: data classification (Green = safe, Yellow = limited, Red = prohibited), no PII/client secrets in public tools, human‑in‑the‑loop sign‑off for external comms, pilots run in “shadow mode” before production.

⸻

3. Operating Model & Roles (RACI)
   • Sponsor: Amanda (sets goals, unblocks resources, hosts monthly exec update).
   • Engagement Lead / AI Consultant: Ching (designs curriculum, runs discovery, builds pilots, defines metrics, owns Friday demos).
   • Function Leads (Sales, Marketing, CSM, Ops, Support): nominate 1 AI Champion each; provide processes, sample data, and sign‑off.
   • IT/Data/Legal: tool access, SSO, data policy review, retention.

Cadence
• Weekly: Mon planning (30m), Tue/Thu build, Fri demo (30–45m).
• Biweekly: Champion Clinic (90m), adoption/metrics review (30m).
• Monthly: Exec Readout (30m) led by Amanda.

⸻

4. Workplan & Timeline (12 weeks)

Phase 1 – Discover & Baseline (Weeks 1–2)
• Intake workshops per function (60–90m each) to map top workflows and pain points.
• Instrument baselines: time studies on 2–3 workflows per function; export current funnel/CS metrics; capture macros/templates in use.
• Select 10 pilot candidates using an Impact × Feasibility scorecard.
• Deliverable: Pilot Backlog v1, Measurement Plan, AI Policy & Guardrails (2‑page).

Phase 2 – Train & Prototype (Weeks 3–6)
• AI Core (2 x 90m) for all participants: prompt patterns, critique loops, verification, retrieval, and safe data use.
• Function Labs (2 x 60m) per team with hands‑on assets (templates, checklists).
• Build 10 pilots in 1‑week sprints (2 per function), with shadow runs in Weeks 4–5 and 3–5 going live by Week 6.
• Deliverable: Friday Demos (recorded), Template Library v1, Pilot scorecards.

Phase 3 – Deploy, Scale, Handoff (Weeks 7–12)
• Productionize best pilots (target 5–7), add monitoring and fallback SOPs.
• Expand to adjacent workflows; create Run Books and Champion Playbooks.
• Build Adoption Dashboard (usage, time saved, quality scores).
• Deliverable: AI Wins Digest (Weeks 8 & 12), Final Report, Roadmap for global rollout.

⸻

5. Measurement & Instrumentation

How we measure
• Time saved: before/after stopwatch on standard tasks (n≥10 samples/workflow).
• Quality: manager review rubric (e.g., accuracy, tone, completeness).
• Funnel: CRM fields (reply rate, meetings booked, cycle time).
• Support: AHT, FRT, deflection %, reopen rate.
• Adoption: weekly active users of templates/agents, prompts per user, completion of AI Core.

Dashboards
• Function KPIs (tiles) + “time saved equivalent FTE” + adoption line chart + list of shipped assets.
• A weekly Top 5 Wins tile (with short Loom clips) for Amanda’s updates.

⸻

6. Training & Enablement (lightweight, practical)

AI Core (all functions)
• Prompt patterns (Role/Goal/Context/Constraints/Examples), critique & iterate, verification & sourcing.
• Retrieval 101: using internal KB safely; how to avoid hallucinations.
• Automation 101: when to push to a button vs. agent; human‑in‑the‑loop gateways.

Function Labs (examples of hands‑on assets)
• Sales: lead research copilot (one‑click country snapshot + decision maker bio), 3‑email personalization pack, objection‑handling guide with policy‑safe snippets.
• Marketing: content repurposer (webinar → blog → LI post → CN/EN variants), campaign UTM copy generator, SEO brief creator for “Hire in [Country]” pages.
• CSM: account health summarizer (usage + tickets + notes → next best action), renewal prep pack (QBR deck outline + risks callouts).
• Operations: document parser for onboarding packs (extract fields to CRM/ERP), exception triage assistant (flags anomalies), forecast explainer (BI → plain‑language insights).
• Support: triage router (intent + priority + suggested macro), answer quality checker (policy conformance), self‑serve FAQ generator from ticket clusters.

(Each asset shipped as: a template + a “how to use” 1‑pager + short Loom.)

⸻

7. Candidate Pilot Backlog (pick ~10 to start)

Sales 1. Country Quick‑Sheet: auto‑generate “Hiring in X” snapshots (employment types, payroll norms, typical timelines) from vetted internal content → attached to outbound. 2. Personalized Outbound: 3‑touch sequence tailored to persona/industry with compliant claims; AE approves/edit.

Marketing 3) Repurpose Engine: turn a long‑form source into CN/EN multi‑channel assets with style guardrails. 4) Programmatic SEO Briefs: generate outlines/FAQs for “Hire in [Country]” search intents; handoff to writers.

CSM 5) Health Check Assistant: weekly account summary with risks and “one thing to do” → sent via Slack/Email. 6) Renewal/QBR Pack: build first‑draft decks + talk tracks from CRM + product usage.

Operations 7) Onboarding Doc Extractor: parse standard forms/contracts into structured fields with 2‑person verification. 8) Payment Exception Triage (tie‑in with Remote Pay): classify, route, and pre‑draft follow‑ups for exceptions.

Support 9) Smart Triage + Suggested Reply: intent/priority labels + draft macro with links to KB; agent approves. 10) Self‑Service Booster: cluster top ticket themes → generate/refresh FAQs and measure deflection.

⸻

8. Tooling Strategy (vendor‑agnostic, China‑aware)
   • Models: support what China can access reliably (e.g., DeepSeek/Kimi/ERNIE) and GPT/Claude when compliant access exists.
   • Where work happens: inside existing tools (CRM, ticketing, BI) via native AI, APIs, or lightweight automations; avoid “yet another app.”
   • Integration options: start no‑code (Zapier/Make/Power Automate) + retrieval over approved KB; graduate to light APIs if needed.
   • Security: SSO, role‑based access, disabled training on customer data, logging for audits.

⸻

9. Governance, Risk & Change Mgmt
   • Policy: 2‑page “AI Acceptable Use” (red/yellow/green data, review thresholds, approval steps).
   • Human‑in‑the‑loop: external comms and legal/compliance outputs always require human sign‑off.
   • Quality gates: spot‑check 5% of AI‑assisted outputs; failure → revert & fix template.
   • Change mgmt: ADKAR lens—awareness (Amanda’s kickoff), desire (quick wins), knowledge/ability (labs + clinics), reinforcement (leaderboard, recognition).

⸻

10. Communications — make Amanda look great
    • Kickoff (Week 1): Amanda opens the “AI‑First China Lighthouse.”
    • Friday Demos: 30–45 minutes; Amanda closes with “what this unlocks.”
    • AI Wins Digest (Weeks 4/8/12): 1‑page with metrics, GIFs/Looms; Amanda forwards to CEO/CTO + global LT.
    • Leadership Readout (Weeks 6 & 12): 30‑minute session led by Amanda; China as the model for global rollout.

⸻

11. Example Metrics Targets (first 12 weeks)
    • Sales: +15% meetings booked/AE; 25% faster lead research; +10% outbound reply rate.
    • Marketing: 30% faster content production; 20% more localized assets shipped/mo.
    • CSM: 2 extra proactive touches/account/month; −15% time to prep QBR.
    • Ops: 40% faster doc processing with ≥99% field accuracy after review.
    • Support: −20% first response time; +10–15% deflection on top 20 FAQs.

⸻

12. Reporting & Artifacts (you’ll hand over)
    • Template Library (≥30 prompts/templates) and Playbooks (10 SOPs).
    • Adoption & Impact Dashboard (Power BI).
    • Pilot Scorecards and Before/After time studies.
    • Handover: Champion Playbook, maintenance plan, backlog for the next 90 days.

⸻

13. Effort & Commercials (pick a package; fee placeholders)

Replace rates with your pricing. These are hour ranges that map cleanly to scope.

Starter (8 weeks) – focused quick wins
• Scope: 6 pilots → 3 productionized, AI Core + 2 Function Labs, dashboard lite.
• Effort: ~90–120 consulting hours.
• Fee: your rate × hours (e.g., at $200/h → $18–24k).

Standard (12 weeks) – recommended
• Scope: 10 pilots → 5–7 productionized, AI Core + 5 Function Labs, full dashboard, Champions program.
• Effort: ~180–240 hours.
• Fee: your rate × hours (e.g., $36–48k @ $200/h).

Plus (12 weeks) – deeper automation/integrations
• Scope: everything in Standard + 2 light integrations (APIs/automations), extra change‑mgmt support.
• Effort: ~260–320 hours.
• Fee: your rate × hours (e.g., $52–64k @ $200/h).

Client time ask (per week): Function lead 1–2h, Champion 2–3h, ICs 30–60m, Amanda 30m.

⸻

14. What I’ll Need From Amanda (Day 1–5)
    1.  Nominate one AI Champion per function (curious, process‑savvy, can spare ~2–3h/wk).
    2.  Tooling access: CRM, ticketing, BI, KB; confirm which LLMs are approved/available in China.
    3.  Sample artifacts: 20 recent outbound emails, 20 tickets, 10 onboarding doc sets, 2 QBR decks.
    4.  Approve the AI Policy & Guardrails draft.
    5.  Calendar holds: Friday Demos, Clinics, Exec readouts.

⸻

15. Draft email you can send Amanda

Subject: AI‑First China Lighthouse – 12‑Week Plan & Next Steps

Hi Amanda,
As discussed, I’ve outlined a 12‑week “AI‑First China Lighthouse” program covering Sales, Marketing, CSM, Operations, and Support. The focus is quick, measurable wins by Week 6 and a clean handover by Week 12 so China can scale independently—and you have a strong story for global rollout.

Highlights:
• 10 pilots, target 5–7 in production by Week 12
• Time‑savings and funnel/SLA metrics instrumented from Week 1
• Weekly Friday demos, biweekly Champion Clinics, monthly exec readouts (you as sponsor)
• Policy/guardrails and a central template library for safe, consistent use

I’ve attached three engagement options (Starter, Standard, Plus) with hours and deliverables. If you’re aligned, I’ll finalize the Week‑by‑Week schedule and we can kick off as soon as your Champions are named.

To get started this week, could you: 1. Name one AI Champion per function 2. Confirm tool access (CRM, ticketing, BI, KB; LLMs approved in China) 3. Share sample artifacts (emails, tickets, onboarding packs, QBRs)

Thanks!
Ching

⸻

Optional: risks & mitigations (for the appendix)
• Resistance or “not faster than doing it myself” → pick high‑volume, low‑ambiguity tasks first; show time studies; Friday demos.
• Hallucinations/compliance → retrieval from internal KB, no public data for red‑class content, human sign‑off on external comms.
• Tool access in China → maintain dual‑model strategy (China‑accessible LLM + global LLM where compliant); keep prompts/templates portable.

⸻

If you want, I can package this into a 1‑page executive brief and a slide template for demos, plus a simple Impact × Feasibility pilot scorecard you can reuse. Would you like those as files you can forward to Amanda?
